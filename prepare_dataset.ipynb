{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/test dataset split\n",
    "\n",
    "This Notebook contains all the code used to prepare the datasets used for the training and test of our DNN models.\n",
    "\n",
    "It takes all the 1431 images with Pneumonia label from the original NIH-CXR-14 dataset.\n",
    "\n",
    "It takes an additional number of NON Pneumonia images in order to satisfy the following requirements:\n",
    "\n",
    "* Train-test split follows the proportion 80-20. In other words, Train set contains 4X the number of images in the test set\n",
    "* Train set is balanced: Pneumonia images are 50% of the train set\n",
    "* Test set is not balanced. The percentage of Pneumonia images is close to what could be expected from CXR of patients admitted to a Hospital. It is in our case 25% of the total in the test set\n",
    "* For no patient we have images both in the train and in test set.\n",
    "\n",
    "Putting these constraints in a linear system, we get the following result:\n",
    "\n",
    "* Total number of images in the train set: 2544\n",
    "* Total number of images in the test set: 636\n",
    "* Total number of Pneumonia images in the train set: 1272\n",
    "* Total number of NON-Pneumonia images in the train set: 1272\n",
    "* Total number of Pneumonia images in the test set: 159\n",
    "* Total number of NON-Pneumonia images in test train set: 477\n",
    "\n",
    "All images pre-processed:\n",
    "* compressed in JPEG, resized to 512x512\n",
    "* packed in files in **Tensorflow TFRecord** format\n",
    "\n",
    "to speed up training and get the maxumim utilization of TPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import random\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of images: 112120\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = '/volb/cxr/images'\n",
    "FILE_ORIG = './Data_Entry_2017.csv'\n",
    "\n",
    "df_orig = pd.read_csv(FILE_ORIG)\n",
    "\n",
    "print('Original number of images:', df_orig.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add other columns to identify pneumonia and not pneumonia\n",
    "def prepare_df_with_all_diseases(f_name):\n",
    "    # add the columns for eac disease (0,1)\n",
    "    full_df = pd.read_csv(f_name)\n",
    "    # remove useless last column\n",
    "    full_df.drop(['Unnamed: 11', 'OriginalImage[Width', 'Height]', \n",
    "              'OriginalImagePixelSpacing[x', 'y]'], axis = 1, inplace=True)\n",
    "    \n",
    "    # add one column per label\n",
    "    all_labels = np.unique(list(chain(*full_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "    all_labels = [x for x in all_labels if len(x)>0]\n",
    "    \n",
    "    for c_label in all_labels:\n",
    "        if len(c_label)>1: # leave out empty labels\n",
    "            full_df[c_label] = full_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = prepare_df_with_all_diseases(FILE_ORIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images with Pneumonia label: 1431\n"
     ]
    }
   ],
   "source": [
    "# select ONLY pneumonia\n",
    "\n",
    "condition = (full_df['Pneumonia'] == 1)\n",
    "\n",
    "pneumonia_df = full_df[condition]\n",
    "\n",
    "N_PNEUMONIA = len(pneumonia_df)\n",
    "\n",
    "print('Total number of images with Pneumonia label:', N_PNEUMONIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First split pneumonia images between test and train datasets\n",
    "#### the split is done in order to have no intersection on Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images will be split between train and test\n",
    "N_PNEUMONIA_TEST = 159\n",
    "N_PNEUMONIA_TRAIN = 1272\n",
    "\n",
    "# select PNEUMONIA images for test, train\n",
    "\n",
    "# We don't want the same Patient ID in train and test, thefore we're using GroupKFold split\n",
    "# split is stratified on Patient ID\n",
    "# total list of Patient ID\n",
    "groups = sorted(pneumonia_df['Patient ID'].values)\n",
    "\n",
    "# 8 is the ratio N_PNEUMONIA_TRAIN/N_PNEUMONIA_TEST, therefore we divide in 9 parts\n",
    "# first 8 parts for train, last for test\n",
    "gkf = GroupKFold(n_splits = int(N_PNEUMONIA_TRAIN/N_PNEUMONIA_TEST) +1) \n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gkf.split(pneumonia_df, groups=groups)):\n",
    "    # we could take any one of the splits, we choose the first\n",
    "    if i == 0:\n",
    "        pne_idxs_train = train_index\n",
    "        pne_idxs_test = test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: number of Pneumonia in train and test is correct\n",
      "Check OK\n",
      "Check: No intersection of Patients between train and test\n",
      "Check OK\n"
     ]
    }
   ],
   "source": [
    "# make some controls\n",
    "\n",
    "print('Check: number of Pneumonia in train and test is correct')\n",
    "assert len(pne_idxs_train) == N_PNEUMONIA_TRAIN\n",
    "assert len(pne_idxs_test) == N_PNEUMONIA_TEST\n",
    "print('Check OK')\n",
    "\n",
    "# no intersection between Patient ID?\n",
    "print('Check: No intersection of Patients between train and test')\n",
    "pne_pid_train = list(pneumonia_df.iloc[pne_idxs_train]['Patient ID'].values)\n",
    "pne_pid_test = list(pneumonia_df.iloc[pne_idxs_test]['Patient ID']. values)\n",
    "assert len(set(pne_pid_train).intersection(set(pne_pid_test))) == 0\n",
    "print('Check OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pne_idxs_train and pne_idxs_test can be used on pneumonia_df to get image name with pneumonia: this is the split train, test set\n",
    "\n",
    "pne_train_image_list = list(pneumonia_df.iloc[pne_idxs_train]['Image Index'].values)\n",
    "pne_test_image_list = list(pneumonia_df.iloc[pne_idxs_test]['Image Index'].values)\n",
    "\n",
    "# now we need to add NON Pneumonia, respecting separation of Patient ID and correct ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add NON pneumonia images to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: No intersection of Patients between non pneumonia test and pneumonia train\n",
      "Check OK\n"
     ]
    }
   ],
   "source": [
    "# now we add to the test set 477 NON pneumonia images, where the Patient ID is NOT in pne_pid_train\n",
    "N_NON_PNE_TEST = 477\n",
    "\n",
    "# select non pneumonia\n",
    "condition = (full_df['Pneumonia'] == 0.)\n",
    "non_pneumonia_df = full_df[condition]\n",
    "\n",
    "# we want only Patient ID (pid) not in TRAIN\n",
    "condition = ~non_pneumonia_df['Patient ID'].isin(pne_pid_train)\n",
    "\n",
    "# we want N_NON_PNE_TEST images for test\n",
    "non_pne_test_df = non_pneumonia_df[condition].sample(n=N_NON_PNE_TEST)\n",
    "\n",
    "# make a check: intersection is null\n",
    "print('Check: No intersection of Patients between non pneumonia test and pneumonia train')\n",
    "non_pne_pid_test = list(non_pne_test_df['Patient ID'].values)\n",
    "assert len(set(non_pne_pid_test).intersection(set(pne_pid_train))) == 0\n",
    "print('Check OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: total images in test are: 477+159\n",
      "Check OK\n",
      "Split NON PNE vs PNE in test set is: 477 vs 159 ratio is: 3.0\n"
     ]
    }
   ],
   "source": [
    "# this is the list of NON pneumonia images to add to the test set\n",
    "non_pne_test_image_list = list(non_pne_test_df['Image Index'].values)\n",
    "\n",
    "print('Check: total images in test are: 477+159')\n",
    "assert len(non_pne_test_image_list) + len(pne_test_image_list) == (477 + 159)\n",
    "print('Check OK')\n",
    "\n",
    "ratio = len(non_pne_test_image_list)/len(pne_test_image_list)\n",
    "print('Split NON PNE vs PNE in test set is:', len(non_pne_test_image_list), 'vs', len(pne_test_image_list), 'ratio is:', ratio)\n",
    "\n",
    "# this is the complete list (pne and non pne for test)\n",
    "test_image_list = non_pne_test_image_list + pne_test_image_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set is not balanced. Pneumonia images are 25% of the total.\n",
    "\n",
    "### Now: complete the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to complete the train set adding NON PNE images to pne_train_image_list\n",
    "# I need to add 1272 NON PNE images\n",
    "# condition:\n",
    "# 1. images must be NON PNE\n",
    "# 2. Patient ID must not be in those of test images\n",
    "# 3. Images must not be in the test set\n",
    "\n",
    "# 1. we use non_pneumonia_df\n",
    "# 2. Patient ID must NOT be in non_pne_test_pid + pne_pid_test == test_pid\n",
    "\n",
    "# this is the list of ALL Patient ID in test set\n",
    "test_pid = non_pne_pid_test + pne_pid_test\n",
    "\n",
    "# first select a list of images satisying 1+2\n",
    "condition = ~non_pneumonia_df['Patient ID'].isin(test_pid)\n",
    "\n",
    "candidate_list = list(non_pneumonia_df[condition]['Image Index'].values)\n",
    "\n",
    "# select only those images not in test image list (condition 3)\n",
    "non_pne_train_image_list = [x for x in candidate_list if x not in test_image_list]\n",
    "\n",
    "# now select ONLY 1272 NON PNE for train\n",
    "N_NON_PNE_TRAIN = 1272\n",
    "non_pne_train_image_list = random.sample(non_pne_train_image_list, N_NON_PNE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split NON PNE vs PNE in train set is: 1272 vs 1272 ratio is: 1.0\n"
     ]
    }
   ],
   "source": [
    "# this is the complete list (pne and non pne) for train\n",
    "train_image_list = non_pne_train_image_list + pne_train_image_list\n",
    "\n",
    "ratio = len(non_pne_train_image_list)/len(pne_train_image_list)\n",
    "\n",
    "print('Split NON PNE vs PNE in train set is:', len(non_pne_train_image_list), 'vs', len(pne_train_image_list), 'ratio is:', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set is balanced 50%-50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: there are no common images between train and test\n",
      "Check OK\n"
     ]
    }
   ],
   "source": [
    "# check that there is no intersection between train and test\n",
    "print('Check: there are no common images between train and test')\n",
    "assert len(set(train_image_list).intersection(set(test_image_list))) == 0\n",
    "print('Check OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label list\n",
    "\n",
    "# order is always non-pneumonia + pneumonia in train and test\n",
    "# first part all zeros (non pneumonia) then all one (pneumonia)\n",
    "train_label_list = list(np.zeros(len(non_pne_train_image_list))) + list(np.ones(len(pne_train_image_list)))\n",
    "test_label_list = list(np.zeros(len(non_pne_test_image_list))) + list(np.ones(len(pne_test_image_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before creating TFREcord files we need to shuffle the lists... to avoid having consequential non-pneu and pneu images !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle train set\n",
    "\n",
    "idxs = np.arange(len(train_label_list))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_label_list = np.array(train_label_list)\n",
    "train_image_list = np.array(train_image_list)\n",
    "\n",
    "# shuffle and back to list\n",
    "train_label_list = list(train_label_list[idxs])\n",
    "train_image_list = list(train_image_list[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle test set\n",
    "\n",
    "idxs = np.arange(len(test_label_list))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "test_label_list = np.array(test_label_list)\n",
    "test_image_list = np.array(test_image_list)\n",
    "\n",
    "# shuffle and back to list\n",
    "test_label_list = list(test_label_list[idxs])\n",
    "test_image_list = list(test_image_list[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in two csv files, for further processing\n",
    "\n",
    "df_train_csv = pd.DataFrame(list(zip(train_image_list, train_label_list)), columns = ['image_name', 'label'])\n",
    "df_test_csv = pd.DataFrame(list(zip(test_image_list, test_label_list)), columns = ['image_name', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv.to_csv('train-submission3.csv')\n",
    "df_test_csv.to_csv('test-submission3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions from TF2 docs\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: image, fname, label (as target)\n",
    "\n",
    "# feature contains the schema: image, image_file_name, label\n",
    "\n",
    "def serialize_example(img, img_idx, label):\n",
    "  feature = {\n",
    "      'image': _bytes_feature(img),\n",
    "      'image_idx': _bytes_feature(img_idx),\n",
    "      'label': _int64_feature(label),\n",
    "  }\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything in a function\n",
    "\n",
    "# how many images for file\n",
    "SIZE = 200\n",
    "# image size (es: 512x512)\n",
    "IMG_PIXEL = 512\n",
    "# directory where we put TFREC files\n",
    "TFREC_DIR = '/volb/cxr/tfrec3-512'\n",
    "\n",
    "def create_tfrec(image_list, label_list, file_prefix='train'):\n",
    "    # imgs to process\n",
    "    IMGS = image_list\n",
    "    label_list = label_list\n",
    "    \n",
    "    CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
    "    \n",
    "    for j in range(CT):\n",
    "        print(); \n",
    "        print('Writing TFRecord %i of %i...'%(j+1, CT))\n",
    "    \n",
    "        tStart = time.time()\n",
    "        \n",
    "        # nmber of images that will go in the file\n",
    "        CT2 = min(SIZE, len(IMGS)-j*SIZE)\n",
    "        \n",
    "        # j here is the number given to the file (starting with 00)\n",
    "        with tf.io.TFRecordWriter(os.path.join(TFREC_DIR, file_prefix + '%.2i-%i.tfrec'%(j,CT2))) as writer:\n",
    "            for k in range(CT2):\n",
    "                index = SIZE*j+k\n",
    "            \n",
    "                # read and preprocess png image\n",
    "                img = cv2.imread(os.path.join(IMAGE_DIR, IMGS[index]))\n",
    "                img = cv2.resize(img, (IMG_PIXEL, IMG_PIXEL), interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "                # encode image as JPEG, to save space and reduce read time\n",
    "                img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n",
    "                name = IMGS[index]\n",
    "            \n",
    "                # get the label\n",
    "                label = label_list[index]\n",
    "            \n",
    "                # build the record\n",
    "                # here the structure is img, image_name, label\n",
    "                # must be aligned to the serialize_example() above defined\n",
    "                example = serialize_example(img, str.encode(name),int(label))\n",
    "                \n",
    "                writer.write(example)\n",
    "            \n",
    "                # print progress\n",
    "                if k%100==0: print('#','',end='')\n",
    "    \n",
    "        tEnd = time.time()\n",
    "    \n",
    "        print('')\n",
    "        print('Elapsed: ', round((tEnd - tStart),1), ' (sec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecords for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 1 of 13...\n",
      "# # \n",
      "Elapsed:  5.1  (sec)\n",
      "\n",
      "Writing TFRecord 2 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 3 of 13...\n",
      "# # \n",
      "Elapsed:  4.8  (sec)\n",
      "\n",
      "Writing TFRecord 4 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 5 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 6 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 7 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 8 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 9 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 10 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 11 of 13...\n",
      "# # \n",
      "Elapsed:  5.0  (sec)\n",
      "\n",
      "Writing TFRecord 12 of 13...\n",
      "# # \n",
      "Elapsed:  4.9  (sec)\n",
      "\n",
      "Writing TFRecord 13 of 13...\n",
      "# # \n",
      "Elapsed:  3.4  (sec)\n"
     ]
    }
   ],
   "source": [
    "create_tfrec(train_image_list, train_label_list, file_prefix='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 1 of 4...\n",
      "# # \n",
      "Elapsed:  4.6  (sec)\n",
      "\n",
      "Writing TFRecord 2 of 4...\n",
      "# # \n",
      "Elapsed:  4.6  (sec)\n",
      "\n",
      "Writing TFRecord 3 of 4...\n",
      "# # \n",
      "Elapsed:  4.5  (sec)\n",
      "\n",
      "Writing TFRecord 4 of 4...\n",
      "# \n",
      "Elapsed:  0.8  (sec)\n"
     ]
    }
   ],
   "source": [
    "create_tfrec(test_image_list, test_label_list, file_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 151336\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9546273 Jan  7 11:29 test00-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9767954 Jan  7 11:30 test01-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9776337 Jan  7 11:30 test02-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 1780421 Jan  7 11:30 test03-36.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9791415 Jan  7 11:28 train00-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9734354 Jan  7 11:28 train01-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9776307 Jan  7 11:28 train02-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9582946 Jan  7 11:28 train03-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9683012 Jan  7 11:28 train04-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9732832 Jan  7 11:29 train05-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9720501 Jan  7 11:29 train06-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9801484 Jan  7 11:29 train07-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9925128 Jan  7 11:29 train08-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9765686 Jan  7 11:29 train09-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9743104 Jan  7 11:29 train10-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 9810831 Jan  7 11:29 train11-200.tfrec\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 6993854 Jan  7 11:29 train12-144.tfrec\n"
     ]
    }
   ],
   "source": [
    "# the list of files produces\n",
    "!ls -l $TFREC_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each file the number of images contained is embedded in the name (ex: -200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
